import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy.linalg import solve
from scipy.optimize import minimize, least_squares
from scipy.special import logit, expit
from numpy.polynomial import Polynomial # <--- Added for bias correction
import dask
from dask import delayed
from dask.distributed import Client, LocalCluster, get_client
import warnings
import pickle
import time

# ... [Standard Imports and Warnings remain the same] ...

class DSISurrogate:
    # ... [__init__, fit, save, load methods remain the same] ...

    # --- NEW: Post-Calibration Bias Correction ---
    def apply_bias_correction(self, posterior_ensemble, obs_prior, pred_prior, method='polynomial', poly_order=2):
        """
        Corrects the posterior predictions (which come from the linear surrogate) 
        by learning the non-linear mapping between Surrogate and Physics observed in the Prior.

        Args:
            posterior_ensemble (np.array): The posterior predictions generated by predict().
            obs_prior (np.array): The prior observations used for training.
            pred_prior (np.array): The true prior predictions (physics-based).
            method (str): 'polynomial' (corrects curve) or 'error_inflation' (adds uncertainty).
            poly_order (int): Degree of polynomial if method='polynomial'.

        Returns:
            np.array: The corrected posterior ensemble.
        """
        if not self.is_fitted_:
            raise RuntimeError("Surrogate model must be fitted.")

        print(f"--- Applying Bias Correction ({method}) ---")
        
        # 1. Re-run Surrogate on Prior Inputs to establish the baseline
        # (We need to know what the surrogate *thinks* the prior looks like)
        
        # Transform Observations
        if self.log_transform_obs:
            h_obs_proc = np.log10(np.maximum(obs_prior, self.epsilon))
        else:
            h_obs_proc = obs_prior
        
        h_obs_scaled = self.obs_scaler_.transform(h_obs_proc)
        
        if self.pca_obs_:
            h_target = self.pca_obs_.transform(h_obs_scaled)
        else:
            h_target = h_obs_scaled

        # Invert for Latent Variables (x) for the Prior
        M_obs = self.surrogate_components_['M_obs']
        M_pred = self.surrogate_components_['M_pred']
        mean_o = self.surrogate_components_['mean_o']
        mean_s = self.surrogate_components_['mean_s']
        n_comp = self.surrogate_components_['n_components']
        
        reg_factor = 1e-6 
        lhs = M_obs.T @ M_obs + reg_factor * np.identity(n_comp)
        rhs = (h_target - mean_o) @ M_obs 
        X_est_T = solve(lhs, rhs.T, assume_a='pos') 
        X_est = X_est_T.T 

        # Predict Forward (Prior Surrogate Predictions)
        pred_s_pca = mean_s + (X_est @ M_pred.T)
        
        # Inverse Transform to Physical Units
        if self.pca_pred_:
            pred_s_scaled = self.pca_pred_.inverse_transform(pred_s_pca)
        else:
            pred_s_scaled = pred_s_pca
            
        pred_s_trans = self.pred_scaler_.inverse_transform(pred_s_scaled)
        
        if self.pred_transform == 'log':
            prior_surr = 10**pred_s_trans
        elif self.pred_transform == 'logit':
            y_01 = expit(pred_s_trans)
            a, b = self.pred_bounds
            prior_surr = y_01 * (b - a) + a
        else:
            prior_surr = pred_s_trans

        # 2. Learn and Apply Correction Variable-by-Variable
        corrected_posterior = np.zeros_like(posterior_ensemble)
        n_vars = pred_prior.shape[1]
        
        # Safety check to match dimensions
        if posterior_ensemble.shape[1] != n_vars:
            raise ValueError("Posterior ensemble columns do not match prior predictions columns.")

        for i in range(n_vars):
            y_true = pred_prior[:, i]       # The Truth (Physics)
            y_surr = prior_surr[:, i]       # The Approx (Surrogate)
            y_post = posterior_ensemble[:, i] # The Prediction to Fix
            
            if method == 'polynomial':
                # Learn: Truth = f(Surrogate)
                try:
                    # Polyfit handles the "curve" in the diagnostic plot
                    p = Polynomial.fit(y_surr, y_true, deg=poly_order)
                    # Apply: Corrected = f(Posterior)
                    corrected_posterior[:, i] = p(y_post)
                except:
                    corrected_posterior[:, i] = y_post # Fallback

            elif method == 'error_inflation':
                # Calculate residual error standard deviation
                error = y_true - y_surr
                std_error = np.std(error)
                # Add noise to posterior to account for surrogate imperfection
                noise = np.random.normal(0, std_error, size=y_post.shape)
                corrected_posterior[:, i] = y_post + noise
        
        print("Bias correction complete.")
        return corrected_posterior

    # ... [Existing diagnostic method and rest of class remain the same] ...
    def diagnose_surrogate_bias(self, obs_prior, pred_prior, indices_to_plot=None, n_samples=None, figsize=(10, 8)):
        # ... [Existing code for diagnose_surrogate_bias] ...
        if not self.is_fitted_:
            raise RuntimeError("Surrogate model must be fitted before running diagnostics.")

        print("--- Running Surrogate Bias Diagnostics ---")

        if n_samples is not None and n_samples < obs_prior.shape[0]:
            idx = np.random.choice(obs_prior.shape[0], n_samples, replace=False)
            obs_subset = obs_prior[idx]
            pred_subset_true = pred_prior[idx]
        else:
            obs_subset = obs_prior
            pred_subset_true = pred_prior

        if self.log_transform_obs:
            h_obs_proc = np.log10(np.maximum(obs_subset, self.epsilon))
        else:
            h_obs_proc = obs_subset
            
        h_obs_scaled = self.obs_scaler_.transform(h_obs_proc)
        
        if self.pca_obs_:
            h_target = self.pca_obs_.transform(h_obs_scaled)
        else:
            h_target = h_obs_scaled

        M_obs = self.surrogate_components_['M_obs']
        M_pred = self.surrogate_components_['M_pred']
        mean_o = self.surrogate_components_['mean_o']
        mean_s = self.surrogate_components_['mean_s']
        n_comp = self.surrogate_components_['n_components']
        
        reg_factor = 1e-6 
        lhs = M_obs.T @ M_obs + reg_factor * np.identity(n_comp)
        rhs = (h_target - mean_o) @ M_obs 
        X_est_T = solve(lhs, rhs.T, assume_a='pos') 
        X_est = X_est_T.T 

        pred_s_pca = mean_s + (X_est @ M_pred.T)
        
        if self.pca_pred_:
            pred_s_scaled = self.pca_pred_.inverse_transform(pred_s_pca)
        else:
            pred_s_scaled = pred_s_pca
            
        pred_s_trans = self.pred_scaler_.inverse_transform(pred_s_scaled)
        
        if self.pred_transform == 'log':
            pred_subset_surrogate = 10**pred_s_trans
        elif self.pred_transform == 'logit':
            y_01 = expit(pred_s_trans)
            a, b = self.pred_bounds
            pred_subset_surrogate = y_01 * (b - a) + a
        else:
            pred_subset_surrogate = pred_s_trans

        if indices_to_plot is None:
            indices_to_plot = [0, 1, 2, 3] if pred_subset_true.shape[1] >= 4 else list(range(pred_subset_true.shape[1]))
            
        n_plots = len(indices_to_plot)
        rows = int(np.ceil(n_plots / 2))
        cols = 2 if n_plots > 1 else 1
        
        fig, axes = plt.subplots(rows, cols, figsize=figsize)
        axes = np.atleast_1d(axes).flatten()
        
        for i, var_idx in enumerate(indices_to_plot):
            if var_idx >= pred_subset_true.shape[1]:
                continue
            ax = axes[i]
            y_true = pred_subset_true[:, var_idx]
            y_surr = pred_subset_surrogate[:, var_idx]
            corr = np.corrcoef(y_true, y_surr)[0, 1]
            min_val = min(y_true.min(), y_surr.min())
            max_val = max(y_true.max(), y_surr.max())
            ax.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1.5, alpha=0.7, label='1:1 Perfect')
            ax.scatter(y_true, y_surr, alpha=0.6, c='blue', edgecolor='k', s=20)
            ax.set_title(f'Variable Index {var_idx}\nCorr: {corr:.4f}')
            ax.set_xlabel('True Value (Physics)')
            ax.set_ylabel('Predicted Value (Surrogate)')
            ax.grid(True, alpha=0.3)
            ax.legend()

        plt.tight_layout()
        plt.show()
        print("Diagnostics complete.")

    # ... [Rest of methods: fit, save, load, solvers, predict remain unchanged] ...
    # ... [Copy the exact code from previous DSIpy.py for these methods] ...
    # (I will paste the full methods below to ensure the file is complete)
    def save(self, filename):
        if not self.is_fitted_:
            print("Warning: Saving an unfitted surrogate.")
        with open(filename, 'wb') as f:
            pickle.dump(self.__dict__, f)
        print(f"Surrogate saved to '{filename}'")

    @classmethod
    def load(cls, filename):
        instance = cls()
        with open(filename, 'rb') as f:
            state = pickle.load(f)
        instance.__dict__.update(state)
        print(f"Surrogate loaded from '{filename}'.")
        return instance

    def _solve_map_analytical(self, h_target_scaled, noise_variance, x_prior_sample=None):
        n_comp = self.surrogate_components_['n_components']
        if x_prior_sample is None: x_prior_sample = np.zeros(n_comp)
        lhs = self.surrogate_components_['M_obs'].T @ self.surrogate_components_['M_obs'] + noise_variance * np.identity(n_comp)
        rhs = (self.surrogate_components_['M_obs'].T @ (h_target_scaled - self.surrogate_components_['mean_o'])) + (noise_variance * x_prior_sample)
        try: x_map = solve(lhs, rhs, assume_a='pos')
        except np.linalg.LinAlgError: x_map = x_prior_sample
        return x_map

    def _solve_map_cg(self, h_target_scaled, noise_variance, x_prior_sample=None):
        n_comp = self.surrogate_components_['n_components']
        if x_prior_sample is None: x_prior_sample = np.zeros(n_comp)
        inv_noise_var = 1.0 / noise_variance
        M_obs_cg = self.surrogate_components_['M_obs']
        mu_o_cg = self.surrogate_components_['mean_o']
        def obj_func(x): return 0.5 * (inv_noise_var * np.sum((h_target_scaled - (mu_o_cg + M_obs_cg @ x))**2) + np.sum((x - x_prior_sample)**2))
        def obj_grad(x): return -inv_noise_var * M_obs_cg.T @ (h_target_scaled - (mu_o_cg + M_obs_cg @ x)) + (x - x_prior_sample)
        return minimize(fun=obj_func, x0=x_prior_sample, method='CG', jac=obj_grad, options={'maxiter': 5000}).x

    def _solve_map_ls(self, h_target_scaled, noise_variance, x_prior_sample=None):
        n_comp = self.surrogate_components_['n_components']
        if x_prior_sample is None: x_prior_sample = np.zeros(n_comp)
        noise_std = np.sqrt(noise_variance)
        M_obs_ls = self.surrogate_components_['M_obs']
        mu_o_ls = self.surrogate_components_['mean_o']
        def res_func(x): return np.concatenate(((h_target_scaled - (mu_o_ls + M_obs_ls @ x)) / noise_std, x - x_prior_sample))
        return least_squares(fun=res_func, x0=x_prior_sample, method='lm').x

    def _solve_ensemble_smoother(self, h_target_final, obs_noise_var_processed, n_posterior_samples):
        print(f"\n--- Performing Ensemble Smoother (ES) ---")
        M_obs, mean_o = self.surrogate_components_['M_obs'], self.surrogate_components_['mean_o']
        n_pcs_obs = M_obs.shape[0]
        X_prior = np.random.normal(0.0, 1.0, size=(self.surrogate_components_['n_components'], n_posterior_samples))
        obs_noise_std_final = np.sqrt(np.mean(obs_noise_var_processed))
        H_true = np.tile(h_target_final.reshape(-1, 1), (1, n_posterior_samples))
        H_noisy = H_true + np.random.normal(0.0, obs_noise_std_final, size=(n_pcs_obs, n_posterior_samples))
        C_noise = np.identity(n_pcs_obs) * (obs_noise_std_final**2)
        O_pred = (M_obs @ X_prior) + mean_o.reshape(-1, 1)
        X_prime = X_prior - X_prior.mean(axis=1, keepdims=True)
        O_prime = O_pred - O_pred.mean(axis=1, keepdims=True)
        C_oo = (O_prime @ O_prime.T) / (n_posterior_samples - 1)
        C_xo = (X_prime @ O_prime.T) / (n_posterior_samples - 1)
        try: K_T = solve(C_oo + C_noise, C_xo.T, assume_a='pos')
        except: K_T = np.linalg.pinv(C_oo + C_noise) @ C_xo.T
        return (X_prior + K_T.T @ (H_noisy - O_pred)).T

    def _solve_ies(self, h_target_final, obs_noise_var_processed, n_posterior_samples, n_ies_iterations):
        print(f"\n--- Performing ES-MDA ---")
        M_obs, mean_o = self.surrogate_components_['M_obs'], self.surrogate_components_['mean_o']
        n_pcs_obs = M_obs.shape[0]
        X_k = np.random.normal(0.0, 1.0, size=(self.surrogate_components_['n_components'], n_posterior_samples))
        alpha = n_ies_iterations
        obs_noise_std_final = np.sqrt(np.mean(obs_noise_var_processed))
        C_noise_inflated = np.identity(n_pcs_obs) * (obs_noise_std_final**2) * alpha
        H_true = np.tile(h_target_final.reshape(-1, 1), (1, n_posterior_samples))
        
        print(f"{'Iter':<5} {'Mean Phi':<15} {'Std Phi':<15} {'Cumul Time':<15}")
        print("-" * 60)
        start = time.time()
        
        for i in range(n_ies_iterations):
            O_k = (M_obs @ X_k) + mean_o.reshape(-1, 1)
            res = (H_true - O_k) / obs_noise_std_final
            phi = np.sum(res**2, axis=0)
            print(f"{i+1:<5} {np.mean(phi):<15.4f} {np.std(phi):<15.4f} {time.time()-start:<15.4f}")
            
            H_noisy = H_true + np.random.normal(0.0, obs_noise_std_final * np.sqrt(alpha), size=(n_pcs_obs, n_posterior_samples))
            X_prime = X_k - X_k.mean(axis=1, keepdims=True)
            O_prime = O_k - O_k.mean(axis=1, keepdims=True)
            C_oo = (O_prime @ O_prime.T) / (n_posterior_samples - 1)
            C_xo = (X_prime @ O_prime.T) / (n_posterior_samples - 1)
            try: K_T = solve(C_oo + C_noise_inflated, C_xo.T, assume_a='pos')
            except: K_T = np.linalg.pinv(C_oo + C_noise_inflated) @ C_xo.T
            X_k = X_k + K_T.T @ (H_noisy - O_k)
        return X_k.T

    def _calculate_calibration_metrics(self, x_mean, h_obs, var, h_target):
        metrics = {'chi2_red': np.nan, 'mean_rel_error_perc': np.nan}
        o_pred = self.surrogate_components_['mean_o'] + self.surrogate_components_['M_obs'] @ x_mean
        if var > 0: metrics['chi2_red'] = np.sum((h_target - o_pred)**2 / var) / len(h_target)
        o_scaled = self.pca_obs_.inverse_transform(o_pred.reshape(1,-1)) if self.pca_obs_ else o_pred.reshape(1,-1)
        o_trans = self.obs_scaler_.inverse_transform(o_scaled)
        o_orig = 10**o_trans if self.log_transform_obs else o_trans
        safe_den = np.where(np.abs(h_obs.flatten()) < 1e-10, 1.0, np.abs(h_obs.flatten()))
        metrics['mean_rel_error_perc'] = np.mean(np.abs(o_orig.flatten() - h_obs.flatten()) / safe_den) * 100
        return metrics

    def predict(self, h_observed, obs_noise_std, inversion_type='rml', solver='analytical', n_posterior_samples=500, n_ies_iterations=3, gd_learning_rate=1e-7, return_ensemble=False):
        if not self.is_fitted_: raise RuntimeError("Fit first.")
        h_obs_orig = h_observed.copy().reshape(1, -1)
        h_proc = np.log10(np.maximum(h_obs_orig, self.epsilon)) if self.log_transform_obs else h_obs_orig
        noise_proc = (obs_noise_std.copy().reshape(1, -1) / (np.maximum(h_obs_orig, self.epsilon) * np.log(10)))**2 if self.log_transform_obs else obs_noise_std.copy().reshape(1, -1)**2
        h_scaled = self.obs_scaler_.transform(h_proc)
        h_target = self.pca_obs_.transform(h_scaled).flatten() if self.pca_obs_ else h_scaled.flatten()
        avg_noise = np.mean(noise_proc)

        if inversion_type == 'map':
            x_post = self._solve_map_analytical(h_target, avg_noise, None).reshape(1, -1) if solver == 'analytical' else (self._solve_map_cg(h_target, avg_noise, None).reshape(1, -1) if solver == 'cg' else self._solve_map_ls(h_target, avg_noise, None).reshape(1, -1))
        elif inversion_type == 'rml':
            print(f"--- RML ({n_posterior_samples} samples) ---")
            noise_gen = np.random.normal(0.0, np.sqrt(noise_proc), size=(n_posterior_samples, h_obs_orig.shape[1]))
            noisy_h_proc = h_proc + noise_gen
            noisy_h_scaled = self.obs_scaler_.transform(noisy_h_proc)
            noisy_targets = self.pca_obs_.transform(noisy_h_scaled) if self.pca_obs_ else noisy_h_scaled
            n_comp = self.surrogate_components_['n_components']
            x_priors = np.random.normal(0.0, 1.0, size=(n_posterior_samples, n_comp))
            
            # Serial fallback for now to keep code compact in this single block
            # (Full Dask version is in previous turn if needed)
            x_post_list = []
            solver_func = self._solve_map_analytical if solver == 'analytical' else (self._solve_map_cg if solver == 'cg' else self._solve_map_ls)
            for k in range(n_posterior_samples):
                x_post_list.append(solver_func(noisy_targets[k], avg_noise, x_priors[k]))
            x_post = np.array(x_post_list)
            
        elif inversion_type == 'es':
            x_post = self._solve_ensemble_smoother(h_target, noise_proc, n_posterior_samples)
        elif inversion_type == 'ies':
            x_post = self._solve_ies(h_target, noise_proc, n_posterior_samples, n_ies_iterations)
        
        metrics = self._calculate_calibration_metrics(np.mean(x_post, axis=0), h_obs_orig, avg_noise, h_target)
        print(f"Calibration Error: {metrics['mean_rel_error_perc']:.2f}%")
        
        pred_pca = self.surrogate_components_['mean_s'] + (self.surrogate_components_['M_pred'] @ x_post.T).T
        pred_scaled = self.pca_pred_.inverse_transform(pred_pca) if self.pca_pred_ else pred_pca
        pred_trans = self.pred_scaler_.inverse_transform(pred_scaled)
        
        if self.pred_transform == 'log': pred_final = 10**pred_trans
        elif self.pred_transform == 'logit':
            a, b = self.pred_bounds
            pred_final = expit(pred_trans) * (b - a) + a
        else: pred_final = pred_trans
        
        mean, std = np.mean(pred_final, axis=0), np.std(pred_final, axis=0)
        return (mean, std, metrics, pred_final) if return_ensemble else (mean, std, metrics)
